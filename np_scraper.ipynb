{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"np_scraper.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Nlz8r_7SLvBy"},"source":["&Lstrok;adowanie potrzebnych bibliotek"]},{"cell_type":"code","metadata":{"id":"E6g0g2GeMBcS"},"source":["from bs4 import BeautifulSoup\n","from requests import get\n","import sqlite3\n","import re\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Mfo6CjcMNKg"},"source":["Definiowanie funkcji, kt&oacute;ra przejdzie przez wszystkie og&lstrok;oszenia (podstrony), pobierze odpowiednie dane i wstawi do kolumn w bazie danych"]},{"cell_type":"code","metadata":{"id":"6IfwSCa6NdlX"},"source":["def parse_page(number):\n","    page = get(f'{url}?pet_page={number}&pet_species=1&pet_weight=0&pet_age=0')\n","    bs = BeautifulSoup(page.content, 'html.parser')\n","    #petla przechodzaca przez wszystkie podstrony z ogloszeniami\n","    for pet in bs.find_all('div', class_='lower-content'):\n","        top_line = pet.find('h3', class_='pets-list-pet-name')\n","        #wyciaganie numeru\n","        pet_number = top_line.find('small').get_text().strip()\n","        #wyciaganie linka do ogloszenia\n","        link = top_line.find('a')\n","        link2 = link['href']\n","        subpage = get(f'https://napaluchu.waw.pl{link2}')\n","        #wejscie na podstrone\n","        bs_sub = BeautifulSoup(subpage.content, 'html.parser')\n","        body = bs_sub.find('section', class_='pets-container')\n","        title = body.find('div', class_='auto-container')\n","        #wyciaganie imienia\n","        pet_name = title.find('h2').get_text().strip().split()\n","        str_name = re.compile(r'[A-Za-z]+')\n","        if str_name.match(pet_name[0]):\n","            pet_name2 = pet_name[0]\n","        else:\n","            pet_name2 = 'brak'\n","        details = body.find('ul', class_='petdetails')\n","        #wyciaganie informacji o rasie\n","        str_breed = re.compile(r'W typie rasy: [\\w]+[ ]?[\\w]*')\n","        breed0 = str_breed.findall(details.find('li').get_text().strip())\n","        if len(breed0) == 0:\n","            breed2 = 'brak'\n","        else:\n","            breed = ' '.join(breed0).split(':')\n","            breed2 = breed[1].strip()\n","        #wyciaganie informacji o wieku\n","        str_age = re.compile(r'Wiek: [0-9]+[ ]?[\\w]*')\n","        age0 =  str_age.findall(body.find('ul', class_='petdetails').get_text().strip())\n","        if len(age0) == 0:\n","            age2 = 'brak'\n","        else:\n","            age = ' '.join(age0).split(':')\n","            age2 = age[1].strip()\n","        #wyciaganie informacji o plci\n","        str_sex = re.compile(r'P\\we\\w: [\\w]+')\n","        sex0 = str_sex.findall(body.find('ul', class_='petdetails').get_text().strip())\n","        if len(sex0) == 0:\n","            sex2 = 'brak'\n","        else:\n","            sex = ' '.join(sex0).split(':')\n","            sex2 = sex[1].strip()\n","        #wyciaganie informacji o wadze\n","        str_weight = re.compile(r'Waga: [\\w ]+')\n","        weight0 = str_weight.findall(body.find('ul', class_='petdetails').get_text().strip())\n","        if len(weight0) == 0:\n","            weight2 = 'brak'\n","        else:\n","            weight = ' '.join(weight0).split(':')\n","            weight2 = weight[1].strip()\n","        #wyciaganie informacji o statusie\n","        str_status = re.compile(r'Status: [\\w ]+')\n","        status0 = str_status.findall(body.find('ul', class_='petdetails').get_text().strip())\n","        if len(status0) == 0:\n","            status2 = 'brak'\n","        else:\n","            status = ' '.join(status0).split(':')\n","            status2 = status[1].strip()\n","        #wyciaganie informacji o dacie przyjecia\n","        str_admission = re.compile(r'Przyj\\wty: [\\w-]+')\n","        admission0 = str_admission.findall(body.find('ul', class_='petdetails').get_text().strip())\n","        if len(admission0) == 0:\n","            admission2 = 'brak'\n","        else:\n","            admission = ' '.join(admission0).split(':')\n","            admission2 = admission[1].strip()\n","        #wyciaganie informacji o dacie wydania\n","        str_release = re.compile(r'Wydany: [\\w-]+')\n","        release0 = str_release.findall(body.find('ul', class_='petdetails').get_text().strip())\n","        if len(release0) == 0:\n","            release2 = 'brak'\n","        else:\n","            release = ' '.join(release0).split(':')\n","            release2 = release[1].strip()\n","        #wyciaganie informacji o miejscu znalezienia\n","        str_found = re.compile(r'Znaleziony: [\\w .,]+')\n","        found0 = str_found.findall(body.find('ul', class_='petdetails').get_text().strip())\n","        if len(found0) == 0:\n","            found2 = 'brak'\n","        else:\n","            found = ' '.join(found0).split(':')\n","            found2 = found[1].strip()\n","        #wyciaganie informacji o boksie\n","        str_kennel = re.compile(r'Boks: [\\w .,()]+')\n","        kennel0 = str_kennel.findall(body.find('ul', class_='petdetails').get_text().strip())\n","        if len(kennel0) == 0:\n","            kennel2 = 'brak'\n","        else:\n","            kennel = ' '.join(kennel0).split(':')\n","            kennel2 = kennel[1].strip()\n","        #wyciaganie informacji o grupie\n","        str_group_ = re.compile(r'Grupa: [\\w .,()-]+')\n","        group_0 = str_group_.findall(body.find('ul', class_='petdetails').get_text().strip())\n","        if len(group_0) ==0:\n","            group_2 = 'brak'\n","        else:\n","            group_ = ' '.join(group_0).split(':')\n","            group_2 = group_[1].strip()\n","        #wrzucanie zmiennych do bazy danych\n","        cur.execute('INSERT INTO pets VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', \n","                    (pet_number, pet_name2, breed2, age2, sex2, weight2, status2, admission2, release2, found2, kennel2, group_2))\n","        time.sleep(2)\n","    con.commit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"avENslarN5zn"},"source":["Definiowanie adresu url, po&lstrok;&aogon;czenie z nowo utworzon&aogon; baz&aogon;, tworzenie tabeli w bazie"]},{"cell_type":"code","metadata":{"id":"4bX63QRvOiUQ"},"source":["url = 'https://napaluchu.waw.pl/zwierzeta/znalazly-dom/'\n","con = sqlite3.connect('na_paluchu.db')\n","cur = con.cursor()\n","\n","cur.execute('DROP TABLE IF EXISTS pets')\n","cur.execute('''CREATE TABLE pets\n","                (numer text, imie text, w_typie_rasy text, wiek text, plec text, waga text, status text, data_przyjecia text, data_wydania text, miejsce_znalezienia text, boks text, grupa text)''')\n","quit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQluvjJKOqIY"},"source":["Tworzenie p&eogon;tli przechodz&aogon;cej przez wszystkie numery stron i zamykanie po&lstrok;&aogon;czenia z baz&aogon; danych."]},{"cell_type":"code","metadata":{"id":"8yK0T3K4ftux"},"source":["for number in range(1, 1335):\n","    time.sleep(1)\n","    parse_page(number)        \n","\n","con.close()"],"execution_count":null,"outputs":[]}]}